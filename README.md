# ETL-пайплайн для погодных данных

В этом проекте сделан ETL-пайплайн для сбора, обработки и загрузки погодных данных. Он может получать данные из API [Open-Meteo](https.open-meteo.com/) или локального JSON-файла, выполнять над ними ряд преобразований и сохранять результат в базу данных PostgreSQL или в CSV-файл.
Весь проект работает в контейнерах на Docker и Docker Compose и настроен для обеспечения простоты развертывания и надежности.

## Основные возможности
*   **Выбор источника данных**: загрузка данных из API или из локального JSON-файла.
*   **Сложная обработка данных**:
    *   Преобразование единиц измерения (имперские -> метрические).
    *   Обработка временных зон и преобразование Unix-времени в ISO 8601.
    *   Обогащение данных суточными агрегатами и агрегатами за светлое время суток.
    *   Оптимизация типов данных для уменьшения потребления памяти.
*   **Выбор получателя данных**: сохранение в PostgreSQL или в локальный CSV-файл.
*   **Надежное окружение**:
    *   Полная изоляция с помощью **Docker**.
    *   Управление секретами через **`.env`** файл.
    *   Автоматическая инициализация базы данных с помощью **`init.sql`**.
    *   Надежный порядок запуска контейнеров благодаря **`healthcheck`**.
*   **Тестирование**: покрытие unit-тестами с использованием `pytest`.
*   **Возможность расширения**: в коде есть возможность дальнейшего развития - выбора широты/долготы точки. Но нужно будет менять модель БД.

## Архитектура и рабочий процесс
1.  **Extract (Извлечение)**: `get_data.py` запрашивает данные из API или читает их из JSON.
2.  **Transform (Преобразование)**: данные проходят через последовательность шагов обработки в памяти.
3.  **Load (Загрузка)**: итоговый DataFrame загружается в PostgreSQL (в таблицу `weather_data`) или сохраняется в `data/final_data.csv`.

## Работа с дублями (повторные записи)
Я выбрал, на мой взгляд, самый надежный и быстрый способ проверки уникальности - ограничение первичного ключа (на данном этапе это таймстемп наблюдения) на уровне таблицы (UNIQUE).
Оно не позволит вставить дубликат записи ни при каких обстоятельствах, даже если в логике приложения есть ошибка или несколько экземпляров приложения пытаются одновременно записать одни и те же данные.

## Установка и запуск

**Требования**: Установленные [Docker](https://www.docker.com/products/docker-desktop/) и [Docker Compose](https://docs.docker.com/compose/install/).

#### Шаг 1: Клонируйте репозиторий
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

#### Шаг 2: Создайте файлы конфигурации
`docker-compose.yml` требует два дополнительных файла в корне проекта:
1.  **`.env`** — для хранения настроек и секретов.
2.  **`init.sql`** — для автоматического создания таблицы в базе данных.

**Создайте файл `.env`:**
```text
# .env
# Настройки для подключения к базе данных PostgreSQL. Например:
DB_USER=admin
DB_PASS=p@$$w0rd
DB_NAME=weather_db
DB_PORT=5432
```
**Вообще, для безопасности кредов, имя этого файла (.env) вносится в .gitignore, чтобы в git не попали ваши логины и пароли. НО! для наглядности я этого не делаю, это же учебный проект)**

**Создайте файл `init.sql`:**
Этот скрипт автоматически создаст таблицу `weather_data` при первом запуске контейнера PostgreSQL.

#### Шаг 3: Соберите Docker-образ
```bash
docker compose build
```

#### Шаг 4: Запустите ETL-пайплайн

Эта команда запустит PostgreSQL, дождется его полной готовности, а затем запустит приложение для выполнения задачи по умолчанию (если она определена в `command` в `docker-compose.yml`).
```bash
docker compose up
```

## Использование

Все команды следует выполнять из корневой директории проекта.

### 1. Запуск unit-тестов
Эта команда создаст временный контейнер и запустит в нем `pytest`.
```bash
docker compose run --rm --entrypoint pytest etl-app
```

### 2. Загрузка данных из API
Выполните эту команду, чтобы скачать данные за нужный период и сохранить их в CSV. **Файл `final_data.csv` появится в папке `data`.**
```bash
docker compose run --rm etl-app api csv --start 2024-05-01 --end 2024-05-10
```

Можно загружать данные сразу в базу данных:
```bash
docker compose run --rm etl-app api db --start 2024-05-01 --end 2024-05-10
```


### 3. Загрузка данных из локального файла JSON
JSON-файл с данными о погоде генерируется в процессе выполнения кода (`weather_data.json`) в папке `data`. Но можно загрузить и свой)

Запустите базу данных в фоновом режиме:
```bash
docker-compose up -d postgres
```
Запустите ETL-скрипт:
```bash
docker-compose run --rm etl-app file db
```
Есть возможность преобразовать и сохранить данные из JSON в CSV:
```bash
docker-compose run --rm etl-app file csv
```

### 4. Подключение к базе данных для проверки
Вы можете подключиться к работающему контейнеру PostgreSQL и проверить данные. Создавать таблицу вручную не нужно.
```bash
# Подключиться к контейнеру с помощью psql
docker-compose exec postgres psql -U admin -d weather_db

# Внутри psql выполнить SQL-запрос для просмотра данных
SELECT time, temperature_2m_celsius, total_rain_24h FROM weather_data LIMIT 10;
```
Чтобы выйти из `psql`, введите `\q`.

### 5. Остановка окружения
Останавливает и удаляет контейнеры.
```bash
docker-compose down
```
Чтобы также удалить все данные из базы данных (том `postgres_data`):
```bash
docker-compose down -v
```

Когда много раз меняешь исходный код (в дев среде, конечно), очень выручает 
```bash
docker compose down -v && docker compose build && docker compose up -d
```
## Структура проекта

```
.
├── data/                    # Директория для хранения данных (JSON, CSV)
├── get_data.py              # Основной ETL-скрипт
├── test_get_data.py         # Unit-тесты для скрипта
├── Dockerfile               # Инструкции для сборки Docker-образа
├── docker-compose.yml       # Файл для оркестрации контейнеров
├── requirements.txt         # Список Python-зависимостей
├── .env                     # Файл с переменными окружения (секреты, настройки)
├── .gitignore               # Файл для git с перечнем файлов, которые нужно игнорировать ;)
├── init.sql                 # Скрипт для инициализации базы данных
└── README.md                # Этот файл
```
